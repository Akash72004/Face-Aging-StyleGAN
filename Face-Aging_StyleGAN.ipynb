{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **üë∂Face Aging with SAM (Style-based Age Manipulation)üë¥**\n",
        "\n",
        "This project demonstrates the use of the official pretrained model from the paper:\n",
        "\n",
        "\"Only a Matter of Style: Age Transformation Using a Style-Based Regression Model\"\n",
        "\n",
        "Authors: Yuval Alaluf, Or Patashnik, Amit H. Bermano - SIGGRAPH 2021\n",
        "\n",
        "arXiv:https://arxiv.org/abs/2102.02754\n",
        "\n",
        "We use the pretrained aging model provided by the authors of the SAM (Style-based Age Manipulation) repository.\n",
        "SAM is built upon StyleGAN and pSp to perform photo-realistic, identity-preserving age transformation by manipulating style vectors in the latent space.\n",
        "\n",
        "This interactive demo allows users to upload a facial image and see a side-by-side aging progression across different target ages."
      ],
      "metadata": {
        "id": "3xgeRtpV5uJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing the Required Packages:**"
      ],
      "metadata": {
        "id": "Dgyc_15e6Nhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio gdown"
      ],
      "metadata": {
        "id": "rtoOQ9bTgg5B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3699cfa-c379-4a6e-92f0-555e5d37d70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cloning the SAM Repository and its Dependencies and Moving into It:**"
      ],
      "metadata": {
        "id": "6kghXvUY6SCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yuval-alaluf/SAM.git\n",
        "%cd SAM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0jgxqUAgjBM",
        "outputId": "46ecd6ab-63ed-4ca4-b0ce-2f3a831e9e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SAM'...\n",
            "remote: Enumerating objects: 228, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 228 (delta 32), reused 22 (delta 22), pack-reused 180 (from 1)\u001b[K\n",
            "Receiving objects: 100% (228/228), 24.63 MiB | 21.87 MiB/s, done.\n",
            "Resolving deltas: 100% (78/78), done.\n",
            "/content/SAM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDji0dZJ9fJL",
        "outputId": "02db44c3-af89-4ffd-f606-94b107215e71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-04 15:42:52--  https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250504%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250504T154252Z&X-Amz-Expires=300&X-Amz-Signature=9588498fb889c0e42effa910c936749be3df79d63982b61f29f9d0921d55d022&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-05-04 15:42:52--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250504%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250504T154252Z&X-Amz-Expires=300&X-Amz-Signature=9588498fb889c0e42effa910c936749be3df79d63982b61f29f9d0921d55d022&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 77854 (76K) [application/octet-stream]\n",
            "Saving to: ‚Äòninja-linux.zip‚Äô\n",
            "\n",
            "ninja-linux.zip     100%[===================>]  76.03K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-05-04 15:42:52 (4.67 MB/s) - ‚Äòninja-linux.zip‚Äô saved [77854/77854]\n",
            "\n",
            "Archive:  ninja-linux.zip\n",
            "  inflating: /usr/local/bin/ninja    \n",
            "update-alternatives: using /usr/local/bin/ninja to provide /usr/bin/ninja (ninja) in auto mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries:**"
      ],
      "metadata": {
        "id": "0SdubsX66wAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "from argparse import Namespace\n",
        "import torchvision.transforms as transforms\n",
        "import tempfile\n",
        "\n",
        "from models.psp import pSp\n",
        "from utils.common import tensor2im\n",
        "from datasets.augmentations import AgeTransformer\n",
        "from scripts.align_all_parallel import align_face\n",
        "import dlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmUePJfggN_H",
        "outputId": "7a3cc00e-12d6-45a1-daea-ef86c7af6114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Downloading the Pre-trained Model:**"
      ],
      "metadata": {
        "id": "LyYZOVdM6zwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_pretrained_model():\n",
        "    print(\"Downloading the pretrained model...\")\n",
        "    MODEL_ID = \"1XyumF6_fdAxFmxpFcmPf-q84LU_22EMC\"\n",
        "    MODEL_NAME = \"sam_ffhq_aging.pt\"\n",
        "\n",
        "    save_path = os.path.join(\"pretrained_models\")\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "\n",
        "    model_path = os.path.join(save_path, MODEL_NAME)\n",
        "    os.system(f\"gdown --id {MODEL_ID} -O {model_path}\")\n",
        "\n",
        "    if os.path.exists(model_path):\n",
        "        file_size = os.path.getsize(model_path)\n",
        "        print(f\"Model downloaded successfully. Size: {file_size/1024/1024:.2f} MB\")\n",
        "        return model_path\n",
        "    else:\n",
        "        raise RuntimeError(\"Failed to download the model.\")\n"
      ],
      "metadata": {
        "id": "hHjtgIisgRjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the Model:**"
      ],
      "metadata": {
        "id": "IU-Peifd7uBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_path):\n",
        "    ckpt = torch.load(model_path, map_location='cpu')\n",
        "    opts = ckpt['opts']\n",
        "    opts['checkpoint_path'] = model_path\n",
        "    opts = Namespace(**opts)\n",
        "\n",
        "    net = pSp(opts)\n",
        "    net.eval().cuda()\n",
        "    return net, opts"
      ],
      "metadata": {
        "id": "LIKNwSJLgUPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Face Alignment:**"
      ],
      "metadata": {
        "id": "d-4GYKBL7xKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def align_image(img: Image.Image):\n",
        "    if not os.path.exists(\"shape_predictor_68_face_landmarks.dat\"):\n",
        "        os.system(\"wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\")\n",
        "        os.system(\"bzip2 -dk shape_predictor_68_face_landmarks.dat.bz2\")\n",
        "\n",
        "    with tempfile.NamedTemporaryFile(suffix=\".jpg\", delete=False) as tmp_file:\n",
        "        img.save(tmp_file.name)\n",
        "        image_path = tmp_file.name\n",
        "\n",
        "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
        "    aligned = align_face(image_path, predictor)\n",
        "    return aligned\n"
      ],
      "metadata": {
        "id": "XZbjNc9cgW8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aging Inference:**"
      ],
      "metadata": {
        "id": "FVskzOTW72bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_aging(image: Image.Image):\n",
        "    aligned = align_image(image)\n",
        "    aligned_resized = aligned.resize((256, 256))\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "    ])\n",
        "    input_tensor = transform(aligned).unsqueeze(0).to('cuda')\n",
        "\n",
        "    target_ages = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "    results = [(aligned.resize((256, 256)), \"Original\")]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for age in target_ages:\n",
        "            transformer = AgeTransformer(target_age=age)\n",
        "            age_input = transformer(input_tensor.squeeze(0).cpu()).unsqueeze(0).to(\"cuda\")\n",
        "            result = net(age_input.float(), randomize_noise=False, resize=False)[0]\n",
        "            image_out = tensor2im(result)\n",
        "            results.append((image_out, f\"Age {age}\"))\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "OJBpDVkXgZO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradio Interface Callback:**"
      ],
      "metadata": {
        "id": "AcIxZLvp79mV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_and_respond(img):\n",
        "    return run_aging(img)"
      ],
      "metadata": {
        "id": "Ay4y_LVy5IFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the Model Before Launch:**"
      ],
      "metadata": {
        "id": "8krki0So8G2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = download_pretrained_model()\n",
        "net, opts = load_model(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpNfpD6sgbms",
        "outputId": "dd4f32ed-184b-4225-efdf-41d0f0a09f99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading the pretrained model...\n",
            "Model downloaded successfully. Size: 2165.36 MB\n",
            "Loading SAM from checkpoint: pretrained_models/sam_ffhq_aging.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Launch Gradio App:**"
      ],
      "metadata": {
        "id": "s52oq3Xa8Lpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface(\n",
        "    fn=process_and_respond,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"Upload a Face Image\"),\n",
        "    outputs=gr.Gallery(label=\"Aging Progression\", columns=4, height=\"auto\"),\n",
        "    title=\"IPCV II Mini Project - Face Aging using GAN\",\n",
        "    description=\"Upload a facial image to see the age progression using Style-Based Age Manipulation (SAM).\",\n",
        "    article=\"<div style='text-align: center;'>Made with ‚ù§Ô∏è by <strong>Ananya, Anusha, Akash & Dhawal</strong></div>\"\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "XK4LQE7l8Cib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch(debug=True, share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "MZFGSposgeY-",
        "outputId": "75c23b8f-6b78-4107-e1fa-e996158c1ea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://8b543c0d564178b6ed.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8b543c0d564178b6ed.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://8b543c0d564178b6ed.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}